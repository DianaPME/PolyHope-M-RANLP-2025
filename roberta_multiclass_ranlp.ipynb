{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 10717,
     "status": "ok",
     "timestamp": 1745365318823,
     "user": {
      "displayName": "Diana Patricia Madera Esp\u00edndola",
      "userId": "01942114537042407486"
     },
     "user_tz": 360
    },
    "id": "mEl8taNDy4Ju"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U72ULHQKzw8B"
   },
   "source": [
    "## Reading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1392,
     "status": "ok",
     "timestamp": 1745365387404,
     "user": {
      "displayName": "Diana Patricia Madera Esp\u00edndola",
      "userId": "01942114537042407486"
     },
     "user_tz": 360
    },
    "id": "E3J7vaA5zODI"
   },
   "outputs": [],
   "source": [
    "file_path= 'dataset_merged_ranlp.csv'\n",
    "df= pd.read_csv(file_path)\n",
    "# Filter by train dataset\n",
    "train_df = df[df['source'] == 'train']\n",
    "# Filter by dev dataset\n",
    "dev_df = df[df['source'] == 'dev']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "22B1sQyqz1f7"
   },
   "source": [
    "## Multiclass Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1745365396169,
     "user": {
      "displayName": "Diana Patricia Madera Esp\u00edndola",
      "userId": "01942114537042407486"
     },
     "user_tz": 360
    },
    "id": "hsrAG0qRz0hP"
   },
   "outputs": [],
   "source": [
    "target_names= ['0','1', '2', '3']\n",
    "class_names= ['Not Hope','Generalized Hope', 'Realistic Hope','Unrealistic Hope']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 236,
     "status": "ok",
     "timestamp": 1745365398107,
     "user": {
      "displayName": "Diana Patricia Madera Esp\u00edndola",
      "userId": "01942114537042407486"
     },
     "user_tz": 360
    },
    "id": "nZOomvtjz6Lx"
   },
   "outputs": [],
   "source": [
    "def map_label(row):\n",
    "    if row['multiclass']=='Not Hope':\n",
    "        return 0\n",
    "    elif row['multiclass']=='Generalized Hope':\n",
    "        return 1\n",
    "    elif row['multiclass']=='Realistic Hope':\n",
    "        return 2\n",
    "    elif row['multiclass']=='Unrealistic Hope':\n",
    "        return 3\n",
    "\n",
    "train_df = train_df.assign(label= train_df.apply(map_label, axis=1))\n",
    "dev_df = dev_df.assign(label= dev_df.apply(map_label, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 20804,
     "status": "ok",
     "timestamp": 1745365462186,
     "user": {
      "displayName": "Diana Patricia Madera Esp\u00edndola",
      "userId": "01942114537042407486"
     },
     "user_tz": 360
    },
    "id": "svRAhI3RL8u5"
   },
   "outputs": [],
   "source": [
    "from simpletransformers.classification import ClassificationModel\n",
    "\n",
    "\n",
    "from simpletransformers.classification import (\n",
    "    MultiLabelClassificationModel, MultiLabelClassificationArgs\n",
    ")\n",
    "import logging\n",
    "\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "transformers_logger = logging.getLogger(\"transformers\")\n",
    "transformers_logger.setLevel(logging.WARNING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1745365497228,
     "user": {
      "displayName": "Diana Patricia Madera Esp\u00edndola",
      "userId": "01942114537042407486"
     },
     "user_tz": 360
    },
    "id": "I5rRQLkF0WB7"
   },
   "outputs": [],
   "source": [
    "def run_ModelTransformer(transformermodel, train, test):\n",
    "    # Create training data in the correct format for SimpleTransformers\n",
    "    train_df = pd.DataFrame({\n",
    "        'text': train['clean_text'],\n",
    "        'labels': train['label']\n",
    "    })\n",
    "\n",
    "    # Ensure labels are integers (needed for SimpleTransformers)\n",
    "    train_df['labels'] = train_df['labels'].astype(int)\n",
    "\n",
    "    # For unlabeled data, we only need the text\n",
    "    test_df = pd.DataFrame({\n",
    "        'text': test['clean_text']\n",
    "    })\n",
    "\n",
    "\n",
    "    # Create a TransformerModel\n",
    "    model = ClassificationModel(\n",
    "        transformermodel[0],\n",
    "        transformermodel[1],\n",
    "        num_labels=4,  \n",
    "        use_cuda=True,\n",
    "        ignore_mismatched_sizes=True,\n",
    "        args={\n",
    "            'num_train_epochs': 3,\n",
    "            'learning_rate': 1e-5,\n",
    "            'max_seq_length': 64,\n",
    "            'use_multiprocessing': False,\n",
    "            'use_multiprocessing_for_evaluation': False,\n",
    "            'overwrite_output_dir': True\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # Train the model with the properly formatted DataFrame\n",
    "    model.train_model(train_df)\n",
    "\n",
    "    # Using predict method instead of eval_model\n",
    "    predictions, raw_outputs = model.predict(test_df['text'].tolist())\n",
    "\n",
    "    # Save predictions to the test DataFrame and export\n",
    "    test['predicted'] = predictions\n",
    "    test.to_csv('multiclass_predictions_ranlp.csv', index=None)\n",
    "\n",
    "    # Output information about the prediction process\n",
    "    print(\"Predictions completed.\")\n",
    "\n",
    "    # Return just the predictions since we can't calculate metrics without true labels\n",
    "    return {\n",
    "        'predictions': predictions\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 707,
     "referenced_widgets": [
      "ae6043ab7b6047eca3a1b06ec7577efa",
      "0b5cf50bdcd54049a3716b5fb2b9c016",
      "294fcab653804a769e19f92a6f241ac9",
      "e60402ef3df14e1b9102d205e09d74fb",
      "3acb12eb30c9405cb118dd1a6f7a4e7f",
      "f64e3188bf724ffdb544d385e9442deb",
      "5f4ed3e2649042b490cf2731b19d6d8f",
      "12d6795db2884be3849219133009a09d",
      "c7dd6294378a4ccba86b1ae66ebab161",
      "a0b7ce60be594062ba6e8a532a20c001",
      "8c3b906c5b0f4946b20f6e5c60c1eea1",
      "a18db81b39f04297bcb47349fb221ec8",
      "b18f5001f7ca4da2b4385901b95ca127",
      "939b9fff54c443aab3901eb171ab3fec",
      "f2bb545f0bbf43eaad8277383e908186",
      "219fe5f550764292bce7d6b456bb6742",
      "961983501edc4b66b013cf90542d2723",
      "97b0de947aa6441896c0161c70e93d2f",
      "460acfc2ec1f43f484a147311db42247",
      "4a106956fea74d4f8c2acbe030b7011f",
      "aba47f2aaed34cd8a8ec762ff331f95d",
      "2fdcb216cc6a43ebaa4fef1285aa45e9",
      "f0ea6150eff84ed0b416c236d448f478",
      "209e3d70a16e40f7bbd01490dff25deb",
      "07d5957095194a2eb98337c6846aa20e",
      "69bd194c533348149814c76e2d56115f",
      "9b136db83eaf4bb2a31499834585d344",
      "42fe13d0da0b47f9abf983303d0eea98",
      "edf34812603b4630b4d809725841d210",
      "883813336b204d32b1d669c525e2ec4a",
      "2c539adbc15d42b0ad491a97c6775269",
      "be03a260dbb2449a9cb77a77b5d275df",
      "2a78a0f61e8c413b83baccf1b84970ee",
      "44a5a891bc684916ad927dc0816058b5",
      "8835c84a45ba46c4bfcf3acc8688841c",
      "5295215a4e44403aa83b1bd5e20e9c87",
      "aae77fcf0f6b4c5abf34d3b9230bb339",
      "59f2638e92484b089a5abfb6e1d4222b",
      "b6fc5c47087c47b79150c7cd970f8180",
      "7c0cf64eec6d450496f5f5d689df9e9d",
      "c66d034be635457d82f6973b9fc7480c",
      "e6ca967df57f4bef9ebd668cdff0cc92",
      "002f615672864f1e9eed1ecf4ddd167d",
      "200175c517bc4cc7a83df5e89ca0bbe0",
      "7c392f31cf294bc1942f3c4a80b8cd40",
      "e80aff71ed8d4edfa35495ef85ca7270",
      "a3c6c2f8c3ed44769c233ce1dbfc884b",
      "905a43e7729944898804eb2e22930ebd",
      "530885fe595f4457acbddc3a2566b73e",
      "7146051938764741826cc3d26361f5f5",
      "455550e5b04744a4b295200ab6db0cef",
      "4835f7e368c94ec58803965753d850ef",
      "cd7fe2eb0096424b8e8e3ab6f49c4482",
      "3e6860302f51402889582a4ce20159ff",
      "1efddfa7409343e3998ec2aa0e0e5297",
      "5bfa159df18c458da6c53fd1521c341c",
      "1daad9eca4c047b883ee2b56772911de",
      "2af55205238e42e99472dcda7b6fed90",
      "7b1d5242f9194a0784e2857a3a2c20f8",
      "38d6616d04994674acc50fdd8ea66b06",
      "98725bc75f0d447c9d2bc68b382a4805",
      "c8191e631c91459c8a3641009818e16f",
      "0eb2e831d8d84e65b2046a271ff2b3e5",
      "2513437cde954484bf438dcd5baef9ce",
      "97b9f6402f294c459a641dcc323b90e4",
      "d1e43633904244fcbd5f3de6cc268e37",
      "b70046b494c64b2fba1aa1949e891435",
      "dd0b424962d74f818b1c951e9bcc63d1",
      "3fe07aa97c74473999e8025980e79381",
      "9d46182f140346a681430a907f23fbc0",
      "c1cbcbcf8ca340aeb75ba490d1101721",
      "55d3b51f207a4a2f81bc2b30a939f74c",
      "a6e528e72b3c48b49b6c8075f22cfaec",
      "1603daaa785740adb63825a2eadbdffd",
      "1723f98966aa4373aafe1dd62d99b052",
      "6bf50270ae5c4509a85abd8e0d255b8a",
      "bb888ea5895749efa7cda1857e04c3af",
      "9ddb049cff7649b596a4ddc943dd2ab8",
      "e49bc18242304477ad1b85aa856fc96b",
      "c98c889d857d4818ab0e0c8720764088",
      "2eba0024e45342458ff34ed4b19dfc2a",
      "bfbc262d561e4635820fcfb51c49da7c",
      "3e1e029f80724e3faa5a4e0e63033168",
      "6613e47ba087420c9cb68b2ee82dfa14",
      "0c3074618e7149da84da8c8ec11ff107",
      "fdd0617f0e6f4702946a2456bff20f96",
      "d34749152882435c9e10805d437f8b36",
      "3045447738874091ad153d26d3766843",
      "645b7a57bd6942e6a6e9c558c755ccb1",
      "c510bc3fd4e348da9222945f6b990586",
      "f502a76a97394b3794e56309391e459f",
      "bf1991ff901548e2bb463208ea45d04d",
      "dfc95924ca3941fdaa365b4c62ddc7a1",
      "a25d21c9e66642709257520ecdd688a7",
      "3004f6ebdd0d4e6a8013dae6c27ffde5",
      "b10f07926df3485daf1c7ef194048ee2",
      "862a901bf2c24a55aa1ca632879ee596",
      "9a2e591e1ab54e7e97125b4601265a8c",
      "ed6d4729f3de4471b3f3516887639e18"
     ]
    },
    "executionInfo": {
     "elapsed": 2939562,
     "status": "ok",
     "timestamp": 1745368436789,
     "user": {
      "displayName": "Diana Patricia Madera Esp\u00edndola",
      "userId": "01942114537042407486"
     },
     "user_tz": 360
    },
    "id": "WApXT6ZJ0ZKo",
    "outputId": "1705be3c-f751-429d-ce3a-dda1dc0e1637"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae6043ab7b6047eca3a1b06ec7577efa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/615 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a model of type xlm-roberta to instantiate a model of type roberta. This is not supported for all configurations of models and can yield errors.\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "WARNING:huggingface_hub.file_download:Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a18db81b39f04297bcb47349fb221ec8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.12G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0ea6150eff84ed0b416c236d448f478",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44a5a891bc684916ad927dc0816058b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/9.10M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'XLMRobertaTokenizer'. \n",
      "The class this function is called from is 'RobertaTokenizerFast'.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c392f31cf294bc1942f3c4a80b8cd40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/simpletransformers/classification/classification_model.py:882: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = amp.GradScaler()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5bfa159df18c458da6c53fd1521c341c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 1 of 3:   0%|          | 0/4887 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/simpletransformers/classification/classification_model.py:905: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast():\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b70046b494c64b2fba1aa1949e891435",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 2 of 3:   0%|          | 0/4887 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ddb049cff7649b596a4ddc943dd2ab8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Epoch 3 of 3:   0%|          | 0/4887 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "645b7a57bd6942e6a6e9c558c755ccb1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/114 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/simpletransformers/classification/classification_model.py:2188: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions completed for unlabeled test data.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'predictions': array([1, 2, 3, ..., 3, 2, 1])}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_ModelTransformer(['roberta', 'xlm-roberta-base'],train_df, dev_df)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyMduUPfdhfbYe860q8XCbyA",
   "gpuType": "T4",
   "mount_file_id": "1JaqY6e5D2GLoOK_OIfGo0zDo8fvt0LyO",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}